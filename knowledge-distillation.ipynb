{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\n# Check if the current `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n# is available, and if not, use the CPU\ndevice = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:11:40.721166Z","iopub.execute_input":"2025-07-21T08:11:40.721433Z","iopub.status.idle":"2025-07-21T08:11:48.602428Z","shell.execute_reply.started":"2025-07-21T08:11:40.721406Z","shell.execute_reply":"2025-07-21T08:11:48.601599Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.\ntransforms_cifar = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Loading the CIFAR-10 dataset:\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:12:04.780116Z","iopub.execute_input":"2025-07-21T08:12:04.780869Z","iopub.status.idle":"2025-07-21T08:12:10.333082Z","shell.execute_reply.started":"2025-07-21T08:12:04.780844Z","shell.execute_reply":"2025-07-21T08:12:10.332514Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 79.3MB/s] \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Dataloaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:12:25.659112Z","iopub.execute_input":"2025-07-21T08:12:25.659371Z","iopub.status.idle":"2025-07-21T08:12:25.663743Z","shell.execute_reply.started":"2025-07-21T08:12:25.659352Z","shell.execute_reply":"2025-07-21T08:12:25.663015Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Deeper neural network class to be used as teacher:\nclass DeepNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(DeepNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(2048, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Lightweight neural network class to be used as student:\nclass LightNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(LightNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(1024, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:12:36.332172Z","iopub.execute_input":"2025-07-21T08:12:36.332932Z","iopub.status.idle":"2025-07-21T08:12:36.341396Z","shell.execute_reply.started":"2025-07-21T08:12:36.332904Z","shell.execute_reply":"2025-07-21T08:12:36.340572Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def train(model, train_loader, epochs, learning_rate, device):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    model.train()\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            # inputs: A collection of batch_size images\n            # labels: A vector of dimensionality batch_size with integers denoting class of each image\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n\n            # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes\n            # labels: The actual labels of the images. Vector of dimensionality batch_size\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n\ndef test(model, test_loader, device):\n    model.to(device)\n    model.eval()\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:12:49.526747Z","iopub.execute_input":"2025-07-21T08:12:49.527020Z","iopub.status.idle":"2025-07-21T08:12:49.533767Z","shell.execute_reply.started":"2025-07-21T08:12:49.527000Z","shell.execute_reply":"2025-07-21T08:12:49.533058Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"torch.manual_seed(42)\nnn_deep = DeepNN(num_classes=10).to(device)\ntrain(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device)\ntest_accuracy_deep = test(nn_deep, test_loader, device)\n\n# Instantiate the lightweight network:\ntorch.manual_seed(42)\nnn_light = LightNN(num_classes=10).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T08:13:01.671381Z","iopub.execute_input":"2025-07-21T08:13:01.671678Z","iopub.status.idle":"2025-07-21T08:14:21.322848Z","shell.execute_reply.started":"2025-07-21T08:13:01.671655Z","shell.execute_reply":"2025-07-21T08:14:21.322117Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 1.3306611029388349\nEpoch 2/10, Loss: 0.8697741729829013\nEpoch 3/10, Loss: 0.6839523877176787\nEpoch 4/10, Loss: 0.5375352533881926\nEpoch 5/10, Loss: 0.4198965826226622\nEpoch 6/10, Loss: 0.3157641481408073\nEpoch 7/10, Loss: 0.23006480274831548\nEpoch 8/10, Loss: 0.17309708939984325\nEpoch 9/10, Loss: 0.14887453753815588\nEpoch 10/10, Loss: 0.12612693728235982\nTest Accuracy: 74.24%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}